# -*- coding: utf-8 -*-
"""Vins.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/156N69-sEgkFRHfZH_BmFWzmx71Rta2U1

Merci de se référer à la réponse à la question 24.

# Étude de marché - Vin _(8 heures)_

Le client, le Domaine des Croix, cherche à se lancer sur le marché américain . Il souhaite donc **définir le prix** de ses bouteilles de vin **pour être compétitif sur le marché américain**. Il a récupéré un jeu de données de 130k bouteilles de vin, avec les cépages, les pays et région de production, les millésimes (c'est-à-dire les années de production), ainsi que des notes ("points") et descriptifs d'oenologues (les spécialistes du vin), et le prix moyen en dollars de toutes ces bouteilles sur le marché américain.

**L'objectif sera de faire une présentation de l'analyse du marché, et du prix que vous conseillez de fixer pour les vins du client.** Le client n'est pas data analyst, mais souhaiterait comprendre la démarche. Il faudra donc s'attacher à expliquer comment les prix ont été fixés, sans rentrer dans un trop grand niveau technique, autrement dit : vulgariser.




## Jeux de données
- Dataset des 130k vins : https://github.com/WildCodeSchool/wilddata/raw/main/wine.zip
- Dataset de la bouteille de vin que le client aimerait proposer sur le marché américain : https://raw.githubusercontent.com/WildCodeSchool/wilddata/main/domaine_des_croix.csv


## Livrables attendus
Le client souhaite une présentation (et non pas du code)
La présentation contiendra a minima ces éléments :
- Rappel du contexte et de la problématique
- Analyse exploratoire des données
- Méthodologie, outils et langages utilisés
- Présentation de la partie technique et du code créé, si code il y a, pour cette analyse
- NLP: Utilisation des descriptions contenues dans le fichier `domaines_des_croix.csv`, en intégrant un "wordcloud" dans votre tableau de bord.
- Votre tableau de bord contient des graphiques.
- Votre tableau de bord contient au moins une visualisation de données interactive.
- Votre tableau de bord contient au moins une carte représentant des informations géographiques.
- Votre tableau de bord contient au moins un tableau croisé.
- L'ensemble des graphiques et visuels doivent être lisible par tous (prise en compte des personne en situation de handicap visuel).
- Réponse à la question métier : proposition de prix ou de fourchette de prix au client pour être correctement positionné face à la concurrence sur le marché américain

Effectuez tout d'abord la trame ci-dessous. Puis, si vous avez des bonnes idées à proposer au client, elles sont évidemment les bienvenues.

## Préparation des données et exploration des données

## Analyse du marché
Le Domaine des Croix souhaiterait une analyse descriptive du marché du vin. Vous allez donc réaliser un ensemble de dataviz, avec l'outil de votre choix (Seaborn, Plotly, Excel, PowerBI, Tableau, etc...). Vous pouvez par exemple intégrer dans votre tableau de bord:
- la répartition du nombre de vins par pays
- les pays qui ont les meilleures notes
- les moyennes de notes par cépage
- la répartition par décile
- etc...

Le client souhaiterait un zoom spécifique sur le cépage ("variety") Pinot Noir.


## Descriptions
Quels sont les mots qui ressortent le plus dans les descriptions des vins ? Et spécifiquement pour le pinot noir, est-ce très différent ?  Et pour la province Burgundi en France ?

## Analyse comparative

L'objectif ici sera de comparer chacun des vins du client par rapport à ses concurrents sur le marché. Par exemple, comparer les tarifs pratiqués pour les vins français, puis de plus en plus précisément, les vins de Bourgogne puisque notre client est en Bourgogne, puis les Pinot Noir bourguignons de la même année.
N'hésitez pas à être original dans la présentation et les dataviz utilisées.

## Proposition de valeur

Avec le tableau de bord que vous lui avez fourni, le client a une idée précise de ses concurrents. Faites lui une proposition de prix en fonction de sa volonté de positionnement (par exemple : "si vous souhaitez vous positionner sur le haut de gamme, les 25% les plus chers de vos concurrents sont à ce tarif, nous vous conseillons donc de vous aligner sur ce prix").

## Qualité esthétique du tableau de bord

Essayez de garder un oeil critique et visuel sur votre tableau de bord. La forme compte autant que le fond pour le client qui n'est pas data analyst. Pensez donc à "vendre" votre analyse. Par exemple, avec des couleurs s'inspirant du milieu vinicole, des dataviz originales, etc...

## C'est à vous de jouer:
"""

import pandas as pd

link = "https://github.com/WildCodeSchool/wilddata/raw/main/wine_df.zip"
df = pd.read_csv(link)

df.head()

bouteille_df = pd.read_csv("https://raw.githubusercontent.com/WildCodeSchool/wilddata/main/domaine_des_croix_df.csv")

bouteille_df

import seaborn as sns
import matplotlib.pyplot as plt

count_by_country = df['country'].value_counts().reset_index()
count_by_country.columns = ['country', 'count']
count_by_country = count_by_country.sort_values(by='count', ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(data=count_by_country, x='country', y='count', order=count_by_country['country'])
plt.xticks(rotation=90)
plt.xlabel('Pays')
plt.ylabel('Nombre de vins')
plt.title('Répartition par pays du nombre de vins')
plt.yscale('log')
plt.show()

# Calculer la note moyenne par pays
mean_score_by_country = df.groupby('country')['points'].mean().reset_index()
top_countries = mean_score_by_country.nlargest(10, 'points')

plt.figure(figsize=(10, 12))
sns.barplot(data=top_countries, x='points', y='country', palette='viridis')
plt.xlabel('Note moyenne')
plt.ylabel('Pays')
plt.title('Top 10 des pays avec les meilleures notes moyennes')

# Afficher les valeurs à côté des barres
for i, score in enumerate(top_countries['points']):
    plt.text(score, i, f"{score:.2f}", ha='left', va='center', fontsize=8)

plt.show()

mean_score_by_variety = df.groupby('variety')['points'].mean().reset_index()
top_varieties = mean_score_by_variety.nlargest(10, 'points')
plt.figure(figsize=(10, 12))
sns.barplot(data=top_varieties, x='points', y='variety', palette='viridis')
plt.xlabel('Note moyenne')
plt.ylabel('Cépage')
plt.title('Top 10 des cépages avec les meilleures notes moyennes')
for i, score in enumerate(top_varieties['points']):
    plt.text(score, i, f"{score:.2f}", ha='left', va='center', fontsize=8)
plt.show()

df['decile'] = pd.qcut(df['points'], q=10, labels=False, duplicates='drop')
plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='decile', bins=10, kde=True)
plt.xlabel('Décile')
plt.ylabel('Nombre de vins')
plt.title('Répartition des notes par déciles')
plt.xticks(range(10), ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10'])
plt.show()

pinot_noir_df = df[df['variety'] == 'Pinot Noir'].copy()
pinot_noir_df.loc[:, 'decile'] = pd.qcut(pinot_noir_df['points'], q=10, labels=False, duplicates='drop')
plt.figure(figsize=(10, 6))
sns.histplot(data=pinot_noir_df, x='decile', bins=10, kde=True)
plt.xlabel('Décile')
plt.ylabel('Nombre de vins')
plt.title('Répartition des notes par déciles pour le cépage Pinot Noir')
plt.xticks(range(10), ['D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10'])
plt.show()

from wordcloud import WordCloud

# Concaténer toutes les descriptions en un seul texte
text = ' '.join(df['description'].dropna().values)

# Créer le WordCloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

# Afficher le WordCloud
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('WordCloud des descriptions')
plt.show()

import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

# Télécharger les ressources nécessaires pour NLTK
nltk.download('vader_lexicon')

# Initialiser le SentimentIntensityAnalyzer
sia = SentimentIntensityAnalyzer()

# Calculer les scores de sentiment pour chaque description
df['sentiment_score'] = df['description'].apply(lambda x: sia.polarity_scores(x)['compound'])

# Définir les seuils pour classer les scores en négatif, neutre ou positif
negative_threshold = -0.05
positive_threshold = 0.05

# Calculer la répartition des sentiments
sentiment_counts = df['sentiment_score'].apply(
    lambda x: 'Negative' if x < negative_threshold else ('Positive' if x > positive_threshold else 'Neutral')
).value_counts()

# Tracer le diagramme à barres pour la répartition des sentiments
plt.figure(figsize=(8, 6))
sentiment_counts.plot(kind='bar', color=['green', 'blue', 'red'])
plt.xlabel('Sentiment')
plt.ylabel('Nombre de descriptions')
plt.title('Répartition des sentiments dans les descriptions')
plt.show()

# Filtrer les données pour la variété "Pinot Noir"
pinot_noir_text = ' '.join(df[df['variety'] == 'Pinot Noir']['description'].values)

# Créer le WordCloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(pinot_noir_text)

# Afficher le WordCloud
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('WordCloud des descriptions pour la variété Pinot Noir')
plt.show()

# Filtrer les données pour la variété "Pinot Noir"
pinot_noir_comments = df[df['variety'] == 'Pinot Noir']['description']

# Calculer les scores de sentiment pour chaque commentaire
sentiment_scores = pinot_noir_comments.apply(lambda x: sia.polarity_scores(x)['compound'])

# Définir les seuils pour classer les scores en négatif, neutre ou positif
negative_threshold = -0.05
positive_threshold = 0.05

# Calculer la répartition des sentiments
sentiment_counts = sentiment_scores.apply(
    lambda x: 'Negative' if x < negative_threshold else ('Positive' if x > positive_threshold else 'Neutral')
).value_counts()

# Tracer le diagramme à barres pour la répartition des sentiments
plt.figure(figsize=(8, 6))
sentiment_counts.plot(kind='bar', color=['green', 'blue', 'red'])
plt.xlabel('Sentiment')
plt.ylabel('Nombre de commentaires')
plt.title('Répartition des sentiments dans les commentaires pour la variété Pinot Noir')
plt.show()

from collections import Counter
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string

# Télécharger les ressources nécessaires pour NLTK
nltk.download('punkt')
nltk.download('stopwords')

# Récupérer les stopwords en anglais
stopwords_en = set(stopwords.words('english'))

# Fonction pour supprimer la ponctuation et les stopwords
def preprocess_text(text):
    # Supprimer la ponctuation
    text = text.translate(str.maketrans('', '', string.punctuation))

    # Tokenisation des mots
    tokens = word_tokenize(text)

    # Supprimer les stopwords
    tokens = [token for token in tokens if token.lower() not in stopwords_en]

    return tokens

# Concaténer toutes les descriptions en un seul texte
all_text = ' '.join(df['description'].dropna().values)

# Prétraitement du texte (suppression de la ponctuation et des stopwords)
preprocessed_tokens = preprocess_text(all_text)

# Compter les occurrences des mots prétraités
word_counts = Counter(preprocessed_tokens)

# Obtenir les 50 mots les plus fréquents
top_50_words = word_counts.most_common(50)

# Afficher le top 50 des mots les plus fréquents
for word, count in top_50_words:
    print(f"{word}: {count}")

# Tracer le diagramme à barres pour le top 50 des mots les plus fréquents
top_words, word_counts = zip(*top_50_words)
plt.figure(figsize=(12, 6))
plt.bar(top_words, word_counts)
plt.xticks(rotation=45)
plt.xlabel('Mots')
plt.ylabel('Nombre d\'occurrences')
plt.title('Top 50 des mots les plus fréquents (sans ponctuation et stopwords)')
plt.tight_layout()
plt.show()

# Filtrer les données pour la variété "Pinot Noir"
pinot_noir_text = ' '.join(df[df['variety'] == 'Pinot Noir']['description'].dropna().values)

# Prétraitement du texte pour la variété "Pinot Noir" (suppression de la ponctuation et des stopwords)
preprocessed_tokens = preprocess_text(pinot_noir_text)

# Compter les occurrences des mots prétraités
word_counts = Counter(preprocessed_tokens)

# Obtenir les 50 mots les plus fréquents
top_50_words = word_counts.most_common(50)

# Afficher le top 50 des mots les plus fréquents
for word, count in top_50_words:
    print(f"{word}: {count}")

# Tracer le diagramme à barres pour le top 50 des mots les plus fréquents
top_words, word_counts = zip(*top_50_words)
plt.figure(figsize=(12, 6))
plt.bar(top_words, word_counts)
plt.xticks(rotation=45)
plt.xlabel('Mots')
plt.ylabel('Nombre d\'occurrences')
plt.title('Top 50 des mots les plus fréquents (sans ponctuation et stopwords) pour la variété Pinot Noir')
plt.tight_layout()
plt.show()

# Concaténer toutes les descriptions en un seul texte pour l'ensemble des descriptions
all_text = ' '.join(df['description'].dropna().values)

# Prétraitement du texte pour l'ensemble des descriptions (suppression de la ponctuation et des stopwords)
preprocessed_tokens = preprocess_text(all_text)

# Compter les occurrences des mots prétraités pour l'ensemble des descriptions
word_counts = Counter(preprocessed_tokens)

# Obtenir les 50 mots les plus fréquents pour l'ensemble des descriptions
top_50_words = word_counts.most_common(50)

# Filtrer les données pour la variété "Pinot Noir"
pinot_noir_text = ' '.join(df[df['variety'] == 'Pinot Noir']['description'].dropna().values)

# Prétraitement du texte pour la variété "Pinot Noir" (suppression de la ponctuation et des stopwords)
preprocessed_tokens_pinot_noir = preprocess_text(pinot_noir_text)

# Compter les occurrences des mots prétraités pour la variété "Pinot Noir"
word_counts_pinot_noir = Counter(preprocessed_tokens_pinot_noir)

# Obtenir les 50 mots les plus fréquents pour la variété "Pinot Noir"
top_50_words_pinot_noir = word_counts_pinot_noir.most_common(50)

# Afficher le top 50 des mots les plus fréquents pour l'ensemble des descriptions
print('Top 50 des mots les plus fréquents pour l\'ensemble des descriptions:')
for word, count in top_50_words:
    print(f"{word}: {count}")

# Afficher le top 50 des mots les plus fréquents pour la variété "Pinot Noir"
print('\nTop 50 des mots les plus fréquents pour la variété Pinot Noir:')
for word, count in top_50_words_pinot_noir:
    print(f"{word}: {count}")

# Tracer le diagramme à barres pour les deux tops de mots les plus fréquents
top_words, word_counts = zip(*top_50_words)
top_words_pinot_noir, word_counts_pinot_noir = zip(*top_50_words_pinot_noir)

plt.figure(figsize=(12, 6))
plt.bar(top_words, word_counts, label='Ensemble des descriptions')
plt.bar(top_words_pinot_noir, word_counts_pinot_noir, label='Variété Pinot Noir')
plt.xticks(rotation=45)
plt.xlabel('Mots')
plt.ylabel('Nombre d\'occurrences')
plt.title('Comparaison des tops 50 des mots les plus fréquents')
plt.legend()
plt.tight_layout()
plt.show()

"""Les avis concernant le Pinot Noir sont certes atypiques."""

# Obtenir les mots uniques de chaque top
unique_words = set([word for word, count in top_50_words])
unique_words_pinot_noir = set([word for word, count in top_50_words_pinot_noir])

# Comparer les mots uniques
common_words = unique_words.intersection(unique_words_pinot_noir)
only_in_all_text = unique_words - common_words
only_in_pinot_noir = unique_words_pinot_noir - common_words

# Afficher les mots communs
print('Mots communs :', common_words)

# Afficher les mots uniques dans l'ensemble des descriptions
print('Mots uniques dans l\'ensemble des descriptions :', only_in_all_text)

# Afficher les mots uniques pour la variété Pinot Noir
print('Mots uniques pour la variété Pinot Noir :', only_in_pinot_noir)

from textblob import TextBlob

# Filtrer les données pour la province "Burgundy"
burgundy_text = ' '.join(df[df['province'] == 'Burgundy']['description'].dropna().values)

# Prétraitement du texte pour la province "Burgundy"
burgundy_tokens = preprocess_text(burgundy_text)

# Concaténer les tokens prétraités en une chaîne de caractères
burgundy_text_preprocessed = ' '.join(burgundy_tokens)

# Effectuer l'analyse de sentiments sur les descriptions prétraitées de la province "Burgundy"
sentiments = TextBlob(burgundy_text_preprocessed).sentiment

# Définir les seuils pour la classification des sentiments
threshold_positive = 0.2
threshold_negative = -0.2

# Classer les sentiments en négatifs, positifs et neutres
if sentiments.polarity > threshold_positive:
    sentiment_class = 'Positif'
elif sentiments.polarity < threshold_negative:
    sentiment_class = 'Négatif'
else:
    sentiment_class = 'Neutre'

# Créer un dictionnaire avec les comptes de chaque classe de sentiment
sentiment_counts = {'Positif': 0, 'Négatif': 0, 'Neutre': 0}
sentiment_counts[sentiment_class] += 1

# Tracer le diagramme en barres des comptes de chaque classe de sentiment
plt.bar(sentiment_counts.keys(), sentiment_counts.values())
plt.xlabel('Classe de sentiment')
plt.ylabel('Nombre de descriptions')
plt.title('Classification des sentiments pour la province "Burgundy"')
plt.show()

# Filtrer les données pour les vins français
french_wines = df[df['country'] == 'France']

# Obtenir les tarifs pratiqués pour les vins français
prices = french_wines['price'].dropna()

# Tracer l'histogramme vertical des tarifs pratiqués pour les vins français
plt.figure(figsize=(10, 6))
plt.hist(prices, bins=20, orientation='vertical', color='skyblue')
plt.xlabel('Nombre de vins')
plt.ylabel('Prix')
plt.title('Comparaison des tarifs pratiqués pour les vins français')
plt.show()

import numpy as np

# Filtrer les données pour les vins de Bourgogne
bourgogne_wines = df[df['province'] == 'Burgundy']

# Filtrer les vins de Bourgogne pour ne conserver que les prix non nuls
bourgogne_prices = bourgogne_wines['price'].dropna()

# Obtenir les valeurs uniques des prix des vins de Bourgogne et leur comptage
unique_prices, counts = np.unique(bourgogne_prices, return_counts=True)

# Créer la figure et les axes du diagramme en barres
fig, ax = plt.subplots(figsize=(10, 6))

# Tracer le diagramme en barres avec les nombre d'occurrences en abscisses et le prix en ordonnées
ax.bar(counts, unique_prices, color='skyblue')

# Définir les limites des axes
ax.set_xlim(0, 70)
ax.set_ylim(0, 1902.00)

# Ajouter des étiquettes aux axes et un titre
ax.set_xlabel('Nombre d\'occurrences')
ax.set_ylabel('Prix')
ax.set_title('Occurrences des prix des vins de Bourgogne')

# Afficher le diagramme en barres
plt.show()

# Créer la figure et les axes du diagramme en barres
fig, ax = plt.subplots(figsize=(10, 6))

# Tracer le diagramme en barres avec les prix en abscisses et le nombre d'occurrences en ordonnées
ax.bar(unique_prices, counts, color='skyblue')

# Définir les limites des axes
ax.set_xlim(0, 1902.0)
ax.set_ylim(0, 70)

# Ajouter des étiquettes aux axes et un titre
ax.set_xlabel('Prix')
ax.set_ylabel('Nombre d\'occurrences')
ax.set_title('Occurrences des prix des vins de Bourgogne')

# Afficher le diagramme en barres
plt.show()

# Filtrer les données pour les vins de Pinot Noir de Bourgogne
pinot_noir_bourgogne = df[(df['variety'] == 'Pinot Noir') & (df['province'] == 'Burgundy')]

# Filtrer les vins de Pinot Noir de Bourgogne pour ne conserver que les prix non nuls
pinot_noir_prices = pinot_noir_bourgogne['price'].dropna()

# Créer la figure et les axes du diagramme en boîte
fig, ax = plt.subplots(figsize=(10, 6))

# Tracer le diagramme en boîte avec les prix du Pinot Noir de Bourgogne
ax.boxplot(pinot_noir_prices, vert=False, widths=0.6, patch_artist=True)

# Définir les limites des axes
ax.set_xlim(0, 3000)

# Ajouter des étiquettes aux axes et un titre
ax.set_xlabel('Prix')
ax.set_ylabel('Pinot Noir de Bourgogne')
ax.set_title('Distribution des prix du Pinot Noir de Bourgogne')

# Afficher le diagramme en boîte
plt.show()

us_wines = df[df['country'] == 'US']
us_prices = us_wines['price']
print(us_prices.tolist())

price_counts = us_prices.value_counts().sort_index(ascending=False)
for price, count in price_counts.items():
    print(f"Prix : {price}, Occurrences : {count}")

french_wines = df[df['country'] == 'France']
french_prices = french_wines['price']
print(french_prices.tolist())
price_counts = french_prices.value_counts().sort_index(ascending=False)
for price, count in price_counts.items():
    print(f"Prix : {price}, Occurrences : {count}")

pip install streamlit





link = "https://github.com/WildCodeSchool/wilddata/raw/main/wine_df.zip"
df = pd.read_csv(link)

bouteille_df = pd.read_csv("https://raw.githubusercontent.com/WildCodeSchool/wilddata/main/domaine_des_croix_df.csv")

# Import des bibliothèques nécessaires
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import plotly.express as px
import types

def main():
    # Chargement des données (avec une fonction de hachage personnalisée)
    @st.cache_data(hash_funcs={types.FunctionType: lambda _: None})  # Utilisez une fonction de hachage basique pour load_data
    def load_data():
        # Charger les données du jeu de données principal
        data = df
        # Charger les données de la bouteille du client
        client_data = bouteille_df
        return data, client_data


    # Récupération des données
    data, client_data = load_data()

    # Titre de l'application
    st.title("Analyse du Marché du Vin")

    # Rappel du contexte et de la problématique
    st.header("Contexte et Problématique")
    st.write("Le Domaine des Croix souhaite se lancer sur le marché américain du vin. Nous allons analyser les données pour recommander un prix compétitif.")

    # Analyse exploratoire des données
    st.header("Analyse Exploratoire des Données")

    # Répartition du nombre de vins par pays
    st.subheader("Répartition des Vins par Pays")
    country_counts = data['country'].value_counts()
    st.bar_chart(country_counts)

    # Pays avec les meilleures notes
    st.subheader("Pays avec les Meilleures Notes")
    best_rated_countries = data.groupby('country')['points'].mean().sort_values(ascending=False).head(10)
    st.bar_chart(best_rated_countries)

    # Moyennes de notes par cépage
    st.subheader("Moyennes de Notes par Cépage")
    variety_avg_points = data.groupby('variety')['points'].mean().sort_values(ascending=False).head(10)
    st.bar_chart(variety_avg_points)

    # Répartition par décile
    st.subheader("Répartition par Décile")
    decile = pd.qcut(data['price'], q=10, labels=False)
    fig, ax = plt.subplots()
    ax.hist(decile, bins=10, edgecolor='k')
    st.pyplot(fig)


    # NLP: Wordcloud pour les descriptions
    st.header("NLP: Wordcloud pour les Descriptions")
    wordcloud = WordCloud(width=800, height=400).generate(' '.join(data['description']))
    st.image(wordcloud.to_array())

    # Tableau de bord interactif
    st.header("Tableau de Bord Interactif")

    # Ajoutez vos éléments interactifs ici, par exemple des widgets Streamlit pour les filtres
    # Sélection du pays
    selected_country = st.selectbox("Sélectionnez un pays", data['country'].unique())

    # Sélection du cépage
    selected_variety = st.selectbox("Sélectionnez un cépage", data['variety'].unique())

    # Curseur pour le positionnement souhaité
    price_positioning = st.slider("Positionnement souhaité (en prix)", min_value=0, max_value=100, step=1, value=50)

    # Réponse à la question métier : proposition de prix
    st.header("Proposition de Prix")

    # Calculez la fourchette de prix recommandée en fonction du positionnement souhaité par le client
    def calculate_price_range(selected_country, selected_variety, price_positioning):
        # Filtrer les données en fonction des sélections de l'utilisateur
        filtered_data = data[(data['country'] == selected_country) & (data['variety'] == selected_variety)]

        # Calculer la fourchette de prix recommandée en fonction du positionnement souhaité
        min_price = filtered_data['price'].quantile(price_positioning / 100)
        max_price = filtered_data['price'].quantile((100 - price_positioning) / 100)

        return min_price, max_price

    if st.button("Calculer la Fourchette de Prix Recommandée"):
        min_price, max_price = calculate_price_range(selected_country, selected_variety, price_positioning)
        st.write(f"Fourchette de Prix Recommandée : De {min_price} à {max_price}")


    # Qualité esthétique du tableau de bord
    st.header("Qualité Esthétique du Tableau de Bord")

    # Personnalisez l'apparence de votre tableau de bord ici

    # Affichage des données du client
    st.header("Données du Client")
    st.write("Données de la bouteille du client :")
    st.write(client_data)

    # Vous pouvez ajouter d'autres sections personnalisées en fonction des besoins du client

    # Exécution de l'application
    if __name__ == '__main__':
        main()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile dashboard.py

!streamlit run dashboard.py

from google.colab import files

# Sélectionnez le fichier .py depuis votre disque local
uploaded = files.upload()

!cat jacques_mikaelian_certification_data_analyst_cas_pratiques.py

!streamlit run jacques_mikaelian_certification_data_analyst_cas_pratiques.py